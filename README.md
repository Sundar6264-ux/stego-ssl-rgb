# ğŸ›°ï¸ stego-ssl-rgb â€” Selfâ€‘Supervised Learning with Steganographic Perturbations

A compact research repo exploring **Barlow Twins** selfâ€‘supervised learning on **CIFARâ€‘10**
with **bitâ€‘plane steganography** used as an *intentional perturbation/augmentation*.
Two variants are provided:
- **Greenâ€‘channel bitâ€‘plane** perturbation, and
- **RGB bitâ€‘plane** perturbation.

The pipeline pretrains an encoder using Barlow Twins (two augmented views), then evaluates
representations with a **linear probe** and **fineâ€‘tuning**; utilities generate **tâ€‘SNE** plots
to visualize separability.

---

## ğŸ“¦ Whatâ€™s inside

```
stego-ssl-rgb/
â”œâ”€ src/
â”‚  â”œâ”€ originalBarlow/                 # Baseline Barlowâ€‘Twins training + eval
â”‚  â”‚  â”œâ”€ Pymain.py                    # SSL pretraining (clean twoâ€‘crop views)
â”‚  â”‚  â”œâ”€ lp.py                        # Linear probe (logistic head on frozen encoder)
â”‚  â”‚  â”œâ”€ ft_p.py, ft_p_light_adamw.py # Full fineâ€‘tune options
â”‚  â”‚  â””â”€ eval_bt.py, tst.py           # Misc eval helpers
â”‚  â”œâ”€ bit_plane_stego_GreenChannel/   # Stego on Green channel
â”‚  â”‚  â”œâ”€ Pretrain_Stego_Model.py      # SSL pretraining (view2 uses bitâ€‘plane stego)
â”‚  â”‚  â”œâ”€ linear_probe_vis.py          # Linear probe + visualization
â”‚  â”‚  â””â”€ Model_Visualize.py           # tâ€‘SNE / feature visualization
â”‚  â””â”€ bitpl_stego_RGB/                # Stego across RGB
â”‚     â”œâ”€ bitplane_stego_train.py      # SSL pretraining with RGB bitâ€‘plane
â”‚     â”œâ”€ ftsne.py, fvis.py            # TSNE and feature viz
â”‚     â””â”€ st_ev.py                     # Evaluation helpers
â”œâ”€ results/                           # Example outputs (accuracy curves, TSNE plots, etc.)
â”œâ”€ requirements.txt                   # Python dependencies
â””â”€ README.md
```

> **Note:** Scripts are intentionally lightweight research drivers. Some flags are hardâ€‘coded in the files;
> adjust values directly or run with `--help` where available.

---

## ğŸ§  Method (highâ€‘level)

1. **Twoâ€‘view SSL** â€” For each image, create two views:
   - `view1`: standard augmentations (crop, flip, color jitter, etc.).
   - `view2`: same base augs **plus bitâ€‘plane steganography** (flip/embed a chosen bitâ€‘plane).
2. **Barlow Twins** â€” Encode both views, project with an MLP, and minimize the crossâ€‘correlation
   objective to align features while reducing redundancy.
3. **Evaluation** â€” Train a **linear probe** on frozen features and optionally **fineâ€‘tune** the full model.
4. **Visualization** â€” Produce **tâ€‘SNE** scatter plots of embeddings during/after training.

---

## ğŸ›  Requirements

- Python **3.9+** (3.11 is fine)
- A recent **PyTorch** + **torchvision** (CPU or CUDA)
- Other Python libs: `numpy`, `Pillow`, `scikit-learn`, `matplotlib`, `tqdm`

Install everything with:

```bash
python -m venv .venv
# Windows: .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt
```

> If your platform needs specific PyTorch wheels (CUDA/cuDNN), prefer the official install selector
> and then `pip install -r requirements.txt --no-deps` to keep your chosen torch/torchvision versions.

---

## ğŸš€ Quickstart

### 1) SSL pretraining (baseline, clean views)
```bash
python src/originalBarlow/Pymain.py
```
- Downloads **CIFARâ€‘10** via `torchvision` on first run.
- Outputs checkpoints and logs (see prints).

### 2) SSL pretraining with **Greenâ€‘channel bitâ€‘plane stego**
```bash
python src/bit_plane_stego_GreenChannel/Pretrain_Stego_Model.py
```

### 3) SSL pretraining with **RGB bitâ€‘plane stego**
```bash
python src/bitpl_stego_RGB/bitplane_stego_train.py
```

### 4) Linear probe / fineâ€‘tune / visualization
```bash
# Linear probe (frozen encoder)
python src/originalBarlow/lp.py

# Full fineâ€‘tune
python src/originalBarlow/ft_p.py               # or ft_p_light_adamw.py

# tâ€‘SNE / feature visualization helpers
python src/bitpl_stego_RGB/ftsne.py
python src/bitpl_stego_RGB/fvis.py
python src/bit_plane_stego_GreenChannel/Model_Visualize.py
```

Artifacts (accuracy curves, TSNE snapshots) will appear under `results/` and alongside the scripts.

---

## ğŸ§ª Notes & Tips

- **Reproducibility:** set seeds inside the scripts if you need strict repeatability.
- **Batch size / LR:** adjust to your hardware. Cosine LR schedulers are common in these scripts.
- **Mixed precision:** some files use `torch.amp` (automatic mixed precision) â€” works on CUDA and recent CPUs.
- **NaNs:** if loss becomes NaN, reduce LR, clip gradients, or relax augmentations.
- **CIFARâ€‘10:** images are 32Ã—32; projectors/backbones assume this input size.

---

## ğŸ“ˆ Example outputs (see `results/`)

- `full_ft_accuracy.png`, `full_ft_train_loss.png`, `full_ft_tsne.png` (greenâ€‘channel variant)
- `tsne_epoch_*.png` (baseline Barlow Twins)
- `tsne_ssl.png` (RGB stego variant)

---

## ğŸ§¾ License & Citation

Add your preferred license (e.g., MIT). If you publish work using this repo, please cite the
original **Barlow Twins** paper and your own project/report accordingly.

---

## ğŸ™ Acknowledgments

- PyTorch & TorchVision for models/datasets
- scikitâ€‘learn for tâ€‘SNE
- Community work on selfâ€‘supervised learning and steganographic data transforms
